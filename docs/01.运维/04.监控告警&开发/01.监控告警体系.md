---
title: 监控告警体系
date: 2024-04-02 10:37:08
permalink: /pages/b0428f/
categories:
  - 运维
  - 监控告警
tags:
  - 监控告警
---

## 前言
目前有比较多的开源运维平台，内置了监控告警服务，我们可以直接结合实际的业务进行部署使用，例如蓝鲸平台/SPUG平台等。这里我们主要介绍下，在自建的k8s集群或者其它分布式系统中，如何快速搭建自己的监控告警平台。

当前比较主流的监控告警平台，很多都是基于Prometheus + Grafana + AlertManager的方案来实现，当前也可以采用 [VictoriaMetrics](https://github.com/VictoriaMetrics/VictoriaMetrics)的监控方案，这里也是目前我这边在运维大规模集群采用的比较多的监控方案。当前比较传统的方案Zabbix/Nagios这些根据实际业务的需求也可以采用，这里就不再进行介绍。

下面我们具体介绍下Prometheus + Grafana + AlertManager的告警体系

## promtheus监控体系介绍

### promtheus监控体系架构

![](/img/monitor/1.png) 

* prometheus server
  这里prometheus server是prometheus的核心，相当于时间序列数据库，负责从`exporter`拉取和存储监控数据，并提供一套灵活的查询语言（PromQL）供用户使用。prometheus server本身也提供了自己的metrics接口。
* alertmanager
  这里alertmanager是报警组件（prometheus配置报警事件的采集规则，alertmanager配置的报警信息的发送规则），用户可以定义基于监控数据的告警规则，规则会触发告警。一旦`alermanager`收到告警，会通过预定义的方式发出告警通知。
* grafana
  这里grafana是监控可视化报表组件。不仅支持prometheus，还支持很多三方数据库，如InfulxDB等。
* exporter
  exporter是用来监控应用并采集metric信息的组件统称，负责收集目标对象（host, 容器等…）的性能数据，并通过HTTP接口供 Prometheus Server获取。
* pushgateway
  pushgateway是数据采用的插件，采用被动推送来获取监控数据，用户可以把把需要监控的数据发送给pushgateway，pushgateway再将数据推送给prometheus server。

### 部署说明
这里，prometheus监控告警体系，可以采用二进制，或者容器化的部署方案。为了简化k8s集群监控告警体系的部署和复杂度，CoreOS公司开发了一套Prometheus-Operator的开源方案，用户可以非常简单的在kubernetes集群中部署Prometheus生态服务，通过简单的声明和配置来管理Promtheus实例，这些配置将响应、创建、配置和管理Prometheus监控实例。


#### prometheus-operator原理

![](/img/monitor/1.png) 

从本质上来讲Prometheus属于是典型的有状态应用，而其有包含了一些自身特有的运维管理和配置管理方式。而这些都无法通过Kubernetes原生提供的应用管理概念实现自动化。Operator的出现简化了这类应用程序的管理复杂度。它在Kubernetes基本的Resource和Controller的概念上，以扩展Kubernetes api的形式。帮助用户创建，配置和管理复杂的有状态应用程序。从而实现特定应用程序的常见操作以及运维自动化。


* Operator： 根据自定义资源（Custom Resource Definition / CRDs）来部署和管理 Prometheus Server，同时监控这些自定义资源事件的变化来做相应的处理，是整个系统的控制中心，也就是我们常用的控制器，可见operater让prometheus更加k8s。

* Prometheus：声明式创建和管理Prometheus Server实例。

* Prometheus Server： Operator根据自定义资源Prometheus类型中定义的内容而部署的Prometheus Server集群，这些自定义资源可以看作是用来管理Prometheus Server集群的 StatefulSets 资源。

* ServiceMonitor：声明指定监控的服务，描述了一组被Prometheus监控的目标列表。该资源通过Labels来选取对应的Service Endpoint，让 Prometheus Server通过选取的 Service来获取Metrics信息。

* Service：简单的说就是Prometheus监控的对象。

* Alertmanager：定义AlertManager deployment期望的状态，Operator确保这个deployment运行时一直与定义保持一致。


#### 部署和资源实例介绍

这里部署请参考官方文档：https://github.com/prometheus-operator/prometheus-operator

* prometheus实例

```bash
[root@yuhaohao ~]# kubectl get prometheuses.monitoring.coreos.com -n monitoring
NAME                    VERSION   DESIRED   READY   RECONCILED   AVAILABLE   AGE
prometheus-prometheus             1         1       True         True        284d
[root@yuhaohao ~]# kubectl get pod -n monitoring |grep prometheus
prometheus-prometheus-prometheus-0               2/2     Running   0          51d
```

* servicemonitor 示例配置

```bash
# 下面以ping-exporter为例，进行了说明servicemonitor和service的配置信息
[root@yuhaohao ~]# kubectl get service -n monitoring ping-exporter -o yaml
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/instance: ping-exporter
    app.kubernetes.io/name: ping-exporter
  name: ping-exporter
  namespace: monitoring
spec:
  ports:
  - name: http
    port: 9427
    protocol: TCP
    targetPort: http
  selector:
    app.kubernetes.io/instance: ping-exporter
    app.kubernetes.io/name: ping-exporter
  type: ClusterIP

[root@yuhaohao ~]# cat ping-exporter-servicemonitor.yaml
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  labels:
    app.kubernetes.io/instance: ping-exporter
    app.kubernetes.io/name: ping-exporter
  name: ping-exporter
  namespace: monitoring
spec:
  # 指定job的标签，可以不设置。
  jobLabel: k8s-app
  endpoints:
  - honorLabels: true
    # 监控数据抓取的时间间隔
    interval: 30s
    # 指定metrics端口，这个port对应services.spec.ports.name
    port: http
  # 监控目标Service所在的命名空间
  namespaceSelector:
    matchNames:
    - monitoring
  # 监控目标Service目标的标签。
  selector:
    # 注意，这个标签要和etcd的service的标签保持一致
    matchLabels:
      app.kubernetes.io/instance: ping-exporter
      app.kubernetes.io/name: ping-exporter
```

![](/img/monitor/3.png)


创建servicemonitor完毕后，此时我们查看prometheus的配置(在prometheus的Status->Configuration)可以发现，自动多了一条job_name的配置：
```bash
- job_name: serviceMonitor/monitoring/ping-exporter/0
  honor_labels: true
  honor_timestamps: true
  scrape_interval: 30s
  scrape_timeout: 10s
  metrics_path: /metrics
  scheme: http
  follow_redirects: true
  enable_http2: true
  relabel_configs:
  - source_labels: [job]
    separator: ;
    regex: (.*)
    target_label: __tmp_prometheus_job_name
    replacement: $1
    action: replace
  - source_labels: [__meta_kubernetes_service_label_app_kubernetes_io_instance, __meta_kubernetes_service_labelpresent_app_kubernetes_io_instance]
    separator: ;
    regex: (ping-exporter);true
    replacement: $1
    action: keep
  - source_labels: [__meta_kubernetes_service_label_app_kubernetes_io_name, __meta_kubernetes_service_labelpresent_app_kubernetes_io_name]
    separator: ;
    regex: (ping-exporter);true
    replacement: $1
    action: keep
  - source_labels: [__meta_kubernetes_endpoint_port_name]
    separator: ;
    regex: http
    replacement: $1
    action: keep
  - source_labels: [__meta_kubernetes_endpoint_address_target_kind, __meta_kubernetes_endpoint_address_target_name]
    separator: ;
    regex: Node;(.*)
    target_label: node
    replacement: ${1}
    action: replace
  - source_labels: [__meta_kubernetes_endpoint_address_target_kind, __meta_kubernetes_endpoint_address_target_name]
    separator: ;
    regex: Pod;(.*)
    target_label: pod
    replacement: ${1}
    action: replace
  - source_labels: [__meta_kubernetes_namespace]
    separator: ;
    regex: (.*)
    target_label: namespace
    replacement: $1
    action: replace
  - source_labels: [__meta_kubernetes_service_name]
    separator: ;
    regex: (.*)
    target_label: service
    replacement: $1
    action: replace
  - source_labels: [__meta_kubernetes_pod_name]
    separator: ;
    regex: (.*)
    target_label: pod
    replacement: $1
    action: replace
  - source_labels: [__meta_kubernetes_pod_container_name]
    separator: ;
    regex: (.*)
    target_label: container
    replacement: $1
    action: replace
  - source_labels: [__meta_kubernetes_pod_phase]
    separator: ;
    regex: (Failed|Succeeded)
    replacement: $1
    action: drop
  - source_labels: [__meta_kubernetes_service_name]
    separator: ;
    regex: (.*)
    target_label: job
    replacement: ${1}
    action: replace
  - source_labels: [__meta_kubernetes_service_label_jobLabel]
    separator: ;
    regex: (.+)
    target_label: job
    replacement: ${1}
    action: replace
  - separator: ;
    regex: (.*)
    target_label: endpoint
    replacement: http
    action: replace
  - source_labels: [__address__]
    separator: ;
    regex: (.*)
    modulus: 1
    target_label: __tmp_hash
    replacement: $1
    action: hashmod
  - source_labels: [__tmp_hash]
    separator: ;
    regex: "0"
    replacement: $1
    action: keep
  kubernetes_sd_configs:
  - role: endpoints
    kubeconfig_file: ""
    follow_redirects: true
    enable_http2: true
    namespaces:
      own_namespace: false
      names:
      - monitoring
```

#### prometheus和servicemonitor关联

Prometheus与ServiceMonitor之间的关联关系使用serviceMonitorSelector定义，在Prometheus中通过标签选择当前需要监控的ServiceMonitor对象。
Prometheus的定义如下所示： 为了能够让Prometheus关联到ServiceMonitor，需要在Pormtheus定义中使用serviceMonitorSelector

为空表示可以关联任意命名空间下的标签，下面是具体的示例说明
```bash
[root@yuhaohao ~]# kubectl get prometheuses.monitoring.coreos.com -n monitoring  -o yaml
apiVersion: v1
items:
- apiVersion: monitoring.coreos.com/v1
  kind: Prometheus
  metadata:
    annotations:
      meta.helm.sh/release-name: prometheus
      meta.helm.sh/release-namespace: monitoring
    creationTimestamp: "2024-01-15T07:35:18Z"
    generation: 5
    labels:
      app.kubernetes.io/component: prometheus
      app.kubernetes.io/instance: prometheus
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: kube-prometheus
      app.kubernetes.io/version: 0.68.0
      helm.sh/chart: kube-prometheus-8.21.2
    name: prometheus-prometheus
    namespace: monitoring
    resourceVersion: "502245405"
    uid: 55ba062e-9397-47b5-aa0c-75f8085a038d
  spec:
    affinity:
      podAntiAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
......
    enableAdminAPI: false
    enableRemoteWriteReceiver: false
    evaluationInterval: 30s
    externalUrl: http://prometheus-prometheus.monitoring:9090/
    image: bitnami/prometheus:2.47.0-debian-11-r26
    imagePullSecrets:
    - name: inner
    listenLocal: false
    logFormat: logfmt
    logLevel: info
    paused: false
    podMetadata:
      labels:
        app.kubernetes.io/component: prometheus
        app.kubernetes.io/name: prometheus
        prometheus: prometheus-prometheus
    podMonitorNamespaceSelector: {}
    podMonitorSelector: {}
    portName: web
    probeNamespaceSelector: {}
    probeSelector: {}
    replicas: 1
    retention: 60d
    routePrefix: /
    ruleNamespaceSelector: {}
    ruleSelector:
      matchLabels:
        prometheus: alertmanager
        role-define: alerts
    scrapeConfigNamespaceSelector: {}
    scrapeConfigSelector: {}
    scrapeInterval: 30s
    securityContext:
      fsGroup: 1001
      runAsUser: 1001
    serviceAccountName: prometheus-prometheus
    serviceMonitorNamespaceSelector: {}
    serviceMonitorSelector: {}
......
```

### Operator管理Alertmanager实例
通过Prometheus Operator管理Alertmanager实例，用户可以通过自定义资源Alertmanager进行定义，如下所示
当replicas大于1时，Prometheus Operator会自动通过集群的方式创建Alertmanager:
```bash
[root@yuhaohao ~]# kubectl get alertmanagers.monitoring.coreos.com -n monitoring -o yaml
apiVersion: v1
items:
- apiVersion: monitoring.coreos.com/v1
  kind: Alertmanager
  metadata:
    annotations:
      meta.helm.sh/release-name: prometheus
      meta.helm.sh/release-namespace: monitoring
    creationTimestamp: "2024-01-15T07:35:18Z"
    generation: 1
    labels:
      app.kubernetes.io/component: alertmanager
      app.kubernetes.io/instance: prometheus
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: kube-prometheus
      app.kubernetes.io/version: 0.68.0
      helm.sh/chart: kube-prometheus-8.21.2
    name: prometheus-alertmanager
    namespace: monitoring
    resourceVersion: "152700636"
    uid: 10e4b2e4-4e5d-4a1a-a289-c8a809894060
  spec:
    affinity:
      podAntiAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - podAffinityTerm:
            labelSelector:
              matchLabels:
                app.kubernetes.io/component: alertmanager
                app.kubernetes.io/instance: prometheus
                app.kubernetes.io/name: kube-prometheus
            topologyKey: kubernetes.io/hostname
          weight: 1
    containers:
    .....
    externalUrl: http://prometheus-alertmanager.monitoring:9093/
    image: bitnami/alertmanager:0.26.0-debian-11-r38
    imagePullSecrets:
    - name: inner
    listenLocal: false
    logFormat: logfmt
    logLevel: info
    paused: false
    podMetadata:
      labels:
        alertmanager: prometheus-alertmanager
        app.kubernetes.io/component: alertmanager
        app.kubernetes.io/name: alertmanager
    portName: web
    replicas: 1
    resources: {}
    retention: 120h
    routePrefix: /
    securityContext:
      fsGroup: 1001
      runAsUser: 1001
    serviceAccountName: prometheus-alertmanager
```





### 告警规则管理

#### 告警规则配置
在Prometheus Operator模式中，告警规则也编程一个通过Kubernetes API声明式创建的一个资源，如下所示：

```bash
[root@yuhaohao ~]# cat k8s-ping-rules.yaml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: k8s-ping-rules
  namespace: monitoring
  labels:
    prometheus: alertmanager
    role-define: alerts
spec:
  groups:
    - name: k8s-ping.rules
      rules:
        - alert: 节点异常无法连通
          expr: ping_loss_ratio{job="ping-exporter"} == 1
          for: 1m
          labels:
            severity: P0
          annotations:
            summary: 集群节点无法连通
            description: "k8s集群主机: {{ $labels.target }} Ping Loss, 检查节点是否宕机."
```

告警规则创建成功后，通过在Prometheus中使用ruleSelector通过选择需要关联的PrometheusRule即可，具体如下：
```bash
[root@yuhaohao ~]# kubectl get prometheuses.monitoring.coreos.com -n monitoring  -o yaml
......
ruleSelector:
    matchLabels:
        prometheus: alertmanager
        role-define: alerts
......
```
Prometheus重新加载配置后，从UI中我们可以查看到通过PrometheusRule自动创建的告警规则配置：
![](/img/monitor/4.png)

#### prometheus和alertmanager关联
通过在Prometheus中使用alerting指定使用的Alertmanager资源即可
```bash
[root@yuhaohao ~]# kubectl get prometheuses.monitoring.coreos.com -n monitoring prometheus-prometheus -o yaml
apiVersion: monitoring.coreos.com/v1
kind: Prometheus
metadata:
  annotations:
    meta.helm.sh/release-name: prometheus
    meta.helm.sh/release-namespace: monitoring
  creationTimestamp: "2024-01-15T07:35:18Z"
  generation: 5
  labels:
    app.kubernetes.io/component: prometheus
    app.kubernetes.io/instance: prometheus
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: kube-prometheus
    app.kubernetes.io/version: 0.68.0
    helm.sh/chart: kube-prometheus-8.21.2
  name: prometheus-prometheus
  namespace: monitoring
  resourceVersion: "502279004"
  uid: 55ba062e-9397-47b5-aa0c-75f8085a038d
spec:
  affinity:
    podAntiAffinity:
      preferredDuringSchedulingIgnoredDuringExecution:
      - podAffinityTerm:
          labelSelector:
            matchLabels:
              app.kubernetes.io/component: prometheus
              app.kubernetes.io/instance: prometheus
              app.kubernetes.io/name: kube-prometheus
          topologyKey: kubernetes.io/hostname
  # 这里制定alerting使用指定的Alertmanager资源
  alerting:
    alertmanagers:
    - name: prometheus-alertmanager
      namespace: monitoring
      pathPrefix: /
      port: http
......
```

### 监控告警常用操作

#### 1.查看告警规则相关配置
```bash
[root@yuhaohao ~]# kubectl get secrets -n monitoring alertmanager-prometheus-alertmanager -o yaml
apiVersion: v1
data:
  alertmanager.yaml: Z2xvYmFsOgogIHJlc29sdmVfdGltZW91dDogNW0KcmVjZWl2ZXJzOgotIG5hbWU6IHdlYmhvb2sKICB3ZWJob29rX2NvbmZpZ3M6CiAgLSBzZW5kX3Jlc29sdmVkOiB0cnVlCiAgICB1cmw6IGh0dHA6Ly8xMC4xOTguMy4yNToyNTI1L2FsZXJ0Ci0gbmFtZTogd2ViaG9va3AwCiAgd2ViaG9va19jb25maWdzOgogICOiDogMzBtCg==
kind: Secret
metadata:
  creationTimestamp: "2024-10-16T03:22:53Z"
  name: alertmanager-prometheus-alertmanager
  namespace: monitoring
  resourceVersion: "489955086"
  uid: d5b23ac5-1778-42ab-a002-af6d0b0bdd75
type: Opaque

# 这里告警规则实际上保持在alertmanager-<name-of-alertmanager-object>的secret中，可以对内容进行base64解码查看
[root@yuhaohao ~]# echo "Z2xvYmFsOgogIHJlc29sdmVfdGltZW91dDogNW0KcmVjZWl2ZXJzOgotIG5hbWU6IHdlYmhvb2sKICB3ZWJob29rX2NvbmZpZ3M6CiAgLSBzZW5kX3Jlc29sdmVkOiB0cnVlCiAgICB1cmw6IGh0dHA6Ly8xMC4xOTguMy4yNToyNTI1L2FsZXJ0Ci0gbmFtZTogd2ViaG9va3AwCiAgd2ViaG9va19jb25maWdzOgogICOiDogMzBtCg==" |base64 -d 
```

#### 修改告警规则并应用
```bash
# 加解码后的alertmanager的配置导出到文件
[root@yuhaohao ~]# echo "Z2xvYmFsOgogIHJlc29sdmVfdGltZW91dDogNW0KcmVjZWl2ZXJzOgotIG5hbWU6IHdlYmhvb2sKICB3ZWJob29rX2NvbmZpZ3M6CiAgLSBzZW5kX3Jlc29sdmVkOiB0cnVlCiAgICB1cmw6IGh0dHA6Ly8xMC4xOTguMy4yNToyNTI1L2FsZXJ0Ci0gbmFtZTogd2ViaG9va3AwCiAgd2ViaG9va19jb25maWdzOgogICOiDogMzBtCg==" |base64 -d  >> alertmanager.yaml

# 清理旧的alertmanager secret
[root@yuhaohao ~]# kubectl delete secrets -n monitoring alertmanager-prometheus-alertmanager

# 应用新的alertmanager secret配置
[root@yuhaohao ~]# kubectl -n monitoring create secret generic alertmanager-prometheus-alertmanager  --from-file ./alertmanager.yaml
```